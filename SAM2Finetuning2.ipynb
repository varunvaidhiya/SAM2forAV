{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9e4ddf-ed31-4562-b094-02c55ddb9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# Read data\n",
    "data_dir = r\"MapillaryVistasV2//\"  # Path to the Mapillary Vistas dataset\n",
    "version = \"v2.0\"  # Change to \"v1.2\" if using the older version\n",
    "\n",
    "# Load configuration (JSON) that contains label information\n",
    "with open(f'config_{version}.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "labels = config['labels']\n",
    "\n",
    "# Prepare dataset list\n",
    "data = []\n",
    "image_dir = os.path.join(data_dir, \"training/images/\")\n",
    "label_dir = os.path.join(data_dir, f\"training/{version}/labels/\")\n",
    "for image_name in os.listdir(image_dir):\n",
    "    image_path = os.path.join(image_dir, image_name)\n",
    "    label_path = os.path.join(label_dir, image_name.replace(\".jpg\", \".png\"))\n",
    "    data.append({\"image\": image_path, \"annotation\": label_path})\n",
    "\n",
    "def read_batch(data):\n",
    "    # Select image\n",
    "    ent = data[np.random.randint(len(data))]  # Choose random entry\n",
    "    Img = np.array(Image.open(ent[\"image\"]))[..., :3]  # Read image (ignoring alpha channel if present)\n",
    "    ann_map = np.array(Image.open(ent[\"annotation\"]))  # Read annotation\n",
    "    \n",
    "    # Resize image\n",
    "    r = np.min([1024 / Img.shape[1], 1024 / Img.shape[0]])  # Scaling factor\n",
    "    Img = cv2.resize(Img, (int(Img.shape[1] * r), int(Img.shape[0] * r)))\n",
    "    ann_map = cv2.resize(ann_map, (int(ann_map.shape[1] * r), int(ann_map.shape[0] * r)), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Get binary masks and points\n",
    "    inds = np.unique(ann_map)[1:]  # Load all indices, ignore background (assuming it's 0)\n",
    "    points = []\n",
    "    masks = []\n",
    "    for ind in inds:\n",
    "        mask = (ann_map == ind).astype(np.uint8)  # Make binary mask corresponding to index ind\n",
    "        masks.append(mask)\n",
    "        coords = np.argwhere(mask > 0)  # Get all coordinates in mask\n",
    "        yx = np.array(coords[np.random.randint(len(coords))])  # Choose random point/coordinate\n",
    "        points.append([[yx[1], yx[0]]])\n",
    "    return Img, np.array(masks), np.array(points), np.ones([len(masks), 1])\n",
    "\n",
    "# Load model\n",
    "sam2_checkpoint = \"sam2_hiera_small.pt\"  # Path to model weight (downloaded from: https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt)\n",
    "model_cfg = \"sam2_hiera_s.yaml\"  # Model config\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")  # Load model\n",
    "predictor = SAM2ImagePredictor(sam2_model)\n",
    "\n",
    "# Set training parameters\n",
    "predictor.model.sam_mask_decoder.train(True)  # Enable training of mask decoder\n",
    "predictor.model.sam_prompt_encoder.train(True)  # Enable training of prompt encoder\n",
    "optimizer = torch.optim.AdamW(params=predictor.model.parameters(), lr=1e-5, weight_decay=4e-5)\n",
    "scaler = torch.cuda.amp.GradScaler()  # Mixed precision\n",
    "\n",
    "# Training loop\n",
    "for itr in range(100000):\n",
    "    with torch.cuda.amp.autocast():  # Cast to mixed precision\n",
    "        image, mask, input_point, input_label = read_batch(data)  # Load data batch\n",
    "        if mask.shape[0] == 0:\n",
    "            continue  # Ignore empty batches\n",
    "        predictor.set_image(image)  # Apply SAM image encoder to the image\n",
    "\n",
    "        # Prompt encoding\n",
    "        mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(\n",
    "            input_point, input_label, box=None, mask_logits=None, normalize_coords=True)\n",
    "        sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n",
    "            points=(unnorm_coords, labels), boxes=None, masks=None)\n",
    "\n",
    "        # Mask decoder\n",
    "        batched_mode = unnorm_coords.shape[0] > 1  # Multi-object prediction\n",
    "        high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n",
    "        low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n",
    "            image_embeddings=predictor._features[\"image_embed\"][-1].unsqueeze(0),\n",
    "            image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n",
    "            sparse_prompt_embeddings=sparse_embeddings,\n",
    "            dense_prompt_embeddings=dense_embeddings,\n",
    "            multimask_output=True,\n",
    "            repeat_image=batched_mode,\n",
    "            high_res_features=high_res_features,\n",
    "        )\n",
    "        prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])  # Upscale the masks to the original image resolution\n",
    "\n",
    "        # Segmentation Loss calculation\n",
    "        gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n",
    "        prd_mask = torch.sigmoid(prd_masks[:, 0])  # Turn logit map to probability map\n",
    "        seg_loss = (-gt_mask * torch.log(prd_mask + 0.00001) - (1 - gt_mask) * torch.log((1 - prd_mask) + 0.00001)).mean()  # Cross entropy loss\n",
    "\n",
    "        # Score loss calculation (Intersection over Union) IOU\n",
    "        inter = (gt_mask * (prd_mask > 0.5)).sum(1).sum(1)\n",
    "        iou = inter / (gt_mask.sum(1).sum(1) + (prd_mask > 0.5).sum(1).sum(1) - inter)\n",
    "        score_loss = torch.abs(prd_scores[:, 0] - iou).mean()\n",
    "        loss = seg_loss + score_loss * 0.05  # Mix losses\n",
    "\n",
    "        # Apply backpropagation\n",
    "        predictor.model.zero_grad()  # Empty gradient\n",
    "        scaler.scale(loss).backward()  # Backpropagate\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()  # Mixed precision\n",
    "\n",
    "        if itr % 1000 == 0:\n",
    "            torch.save(predictor.model.state_dict(), \"model.torch\")\n",
    "            print(\"Saved model at step:\", itr)\n",
    "\n",
    "        # Display results\n",
    "        if itr == 0:\n",
    "            mean_iou = 0\n",
    "        mean_iou = mean_iou * 0.99 + 0.01 * np.mean(iou.cpu().detach().numpy())\n",
    "        print(\"Step:\", itr, \"Accuracy (IOU):\", mean_iou)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
